# taskfile for end user (outside container)

version: '3'

tasks:
  default:
    desc: List all other tasks avalaible for landlubber
    cmds:
      - echo "All cluster-creating tasks need docker to be running"
      - echo "Below you will find list of all tasks available"
      - echo "To run a task use 'task <task-name>'"
      - echo "Start with running 'task init'"
      - echo ""
      - task --list --sort none
    silent: true

  init:
    desc: |
      ->1️⃣  Copy inventory.yml to ./output,
      you can tailor it to your needs,
      to use landlubber you need to add your hcloud token to it
    env:
      IMAGE: "{{.IMAGE}}"
    cmds:
    - |
      mkdir -p ./output
      docker run --rm \
      -v ./output:/landlubber/output \
      {{.IMAGE | default "ghcr.io/pgulb/landlubber:latest"}} \
      task init
    - sed -i s/YOUR_UID/$UID/g ./output/inventory.yml
    - sed -i s/YOUR_GID/$GID/g ./output/inventory.yml
    - chown -R $UID:$GID ./output/
    - echo "after filling inventory file, run 'task deploy' to start landlubber"

  deploy:
    desc: |
      ->2️⃣  Runs landlubber in a container,
      before using this task, use 'task init',
      write your hcloud token in ./output/inventory.yml,
      and replace any values you would want to change
    env:
      IMAGE: "{{.IMAGE}}"
    cmds:
    - |
      mkdir -p ./output
      docker run --rm \
      -v ./output:/landlubber/output \
      {{.IMAGE | default "ghcr.io/pgulb/landlubber:latest"}} \
      task deploy
    preconditions:
      - sh: |
          count=$(grep -o "NODEIP" ./output/inventory.yml | wc -l)
          if [ "$count" -gt 0 ]; then
            exit 0
          else
            exit 1
          fi
        msg: "file ./output/inventory.yml needs NOT to be filled with IPs - run 'task init' first"

  install-kubeconfig:
    desc: |
      ->3️⃣ ⚠️  Run this after running 'task deploy' to copy .kubeconfig to ~/.kube/config,
      WARNING: this will overwrite existing ~/.kube/config
    prompt: 'WARNING: this will overwrite existing ~/.kube/config - Continue?'
    cmds:
    - |
      mkdir -p ./output
      mkdir -p ~/.kube/
      cp ./output/.kubeconfig ~/.kube/config

  apps-info:
    desc: |
      Run this after running 'task deploy' if you need to see again
      how to interact with provisioned applications
    env:
      IMAGE: "{{.IMAGE}}"
    cmds:
    - |
      mkdir -p ./output
      docker run --rm \
      -v ./output:/landlubber/output \
      {{.IMAGE | default "ghcr.io/pgulb/landlubber:latest"}} \
      task post-install-info
    silent: true

  upgrade-k3s:
    desc: Upgrade k3s to latest version
    prompt: 'WARNING: this can lead to downtime or data loss, consider k8s version skew - Continue?'
    env:
      IMAGE: "{{.IMAGE}}"
    cmds:
    - |
      mkdir -p ./output
      docker run --rm \
      -v ./output:/landlubber/output \
      {{.IMAGE | default "ghcr.io/pgulb/landlubber:latest"}} \
      /landlubber/scripts/update_cluster.sh
    silent: true

  kill-pw:
    desc: |
      Kill all kubectl processes to stop any ongoing port-forwarding
    cmds:
    - killall kubectl

  grafana:
    desc: |
      Port-forward grafana to localhost:3000 and open it in your browser
    cmds:
    - kubectl port-forward service/vm-grafana 3000:80 -n victoria-metrics &
    - sleep 2
    - xdg-open 'http://localhost:3000'

  dashboard:
    desc: |
      Port-forward dashboard to https://localhost:8443 and open it in your browser
    cmds:
    - kubectl -n kubernetes-dashboard port-forward svc/kubernetes-dashboard-kong-proxy 8443:443 &
    - sleep 2
    - xdg-open 'https://localhost:8443'

  longhorn:
    desc: |
      Port-forward longhorn UI to http://localhost:8080 and open it in your browser
    cmds:
    - kubectl port-forward service/longhorn-frontend 8080:80 -n longhorn-system &
    - sleep 2
    - xdg-open 'http://localhost:8080'

  kubetail:
    desc: |
      Port-forward kubetail to http://localhost:12345 and open it in your browser
    cmds:
    - kubectl port-forward -n kubetail svc/kubetail 12345:80 &
    - sleep 2
    - xdg-open 'http://localhost:12345'

  cleanup:
    desc: |
      ⚠️  Delete VMs and network from Hetzner Cloud,
      delete files from ./output/
      WARNING: total destruction ahead
    prompt: 'WARNING: removing all VMs, network and output files - Continue?'
    env:
      IMAGE: "{{.IMAGE}}"
    cmds:
    - |
      mkdir -p ./output
      docker run --rm \
      -v ./output:/landlubber/output \
      {{.IMAGE | default "ghcr.io/pgulb/landlubber:latest"}} \
      task cleanup

  init-dev:
    desc: 'DEVELOPMENT: get inventory file'
    cmds:
     - task: init
       vars:
        IMAGE: ll:1

  deploy-dev:
    desc: 'DEVELOPMENT: run landlubber with local image (ll:1)'
    cmds:
     - task: deploy
       vars:
        IMAGE: ll:1

  build-dev:
    desc: 'DEVELOPMENT: build image locally as ll:1'
    cmds:
     - docker build -t ll:1 .

  sh-dev:
    desc: 'DEVELOPMENT: run container interactively'
    cmds:
     - docker run --rm -v ./output:/landlubber/output -it ll:1 bash

  apps-info-dev:
    desc: 'DEVELOPMENT: run post-install-info with ll:1 image'
    cmds:
     - task: apps-info
       vars:
        IMAGE: ll:1
    silent: true

  upgrade-k3s-dev:
    desc: 'DEVELOPMENT: k3s upgrade with ll:1 image'
    cmds:
     - task: upgrade-k3s
       vars:
        IMAGE: ll:1

  cleanup-dev:
    desc: 'DEVELOPMENT: cleanup with local image (ll:1)'
    cmds:
     - task: cleanup
       vars:
        IMAGE: ll:1

  test:
    desc: 'DEVELOPMENT: run Ansible tests with local image (ll:1) and rocky-ansible-tester'
    cmds:
      - mkdir -p ./output
      - docker network create ansible-test
      - |
        docker run -d -v /sys/fs/cgroup:/sys/fs/cgroup:rw \
        --privileged --cgroupns=host \
        --network ansible-test \
        --name ansible-node \
        ghcr.io/pgulb/rocky-ansible-tester:master
      - |
        docker run -it --rm --name ll --network ansible-test \
        -v ./output:/landlubber/output ll:1 task test
      - task: test-clean

  test-clean:
    desc: 'DEVELOPMENT: remove test resources after failed test'
    cmds:
      - docker rm -f ansible-node
      - docker network rm ansible-test
      - rm -rf ./output/*
      - rm -rf ./output/.*

  test-k3d:
    desc: 'DEVELOPMENT: run k8s manifest tests with local image (ll:1) and k3d'
    cmds:
    - mkdir -p ./output
    - k3d cluster create landlubber-test --servers 3
    - k3d kubeconfig get landlubber-test > ./output/.kubeconfig
    - chmod 600 ./output/.kubeconfig
    - |
        docker run -it --rm --name ll --net=host \
        -v ./output:/landlubber/output ll:1 task test-k3d
    - kubectl get po -A
    - kubectl get no
    - |
      kubectl get pods -A --no-headers | grep \
      -v 'Running' | grep -v 'Completed' \
      && exit 1 || echo 'PODS OK'
    - k3d cluster delete landlubber-test
